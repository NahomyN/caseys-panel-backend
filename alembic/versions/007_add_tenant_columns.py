"""Add tenant_id columns for multi-tenancy

Revision ID: 007_add_tenant_columns
Revises: 006_daily_run_stats
Create Date: 2025-08-28 12:30:00.000000

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '007_add_tenant_columns'
down_revision: Union[str, None] = '006_daily_run_stats'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    bind = op.get_bind()
    dialect = bind.dialect.name

    def _has_col(table, col):
        if dialect == 'sqlite':
            rows = bind.execute(sa.text(f"PRAGMA table_info('{table}')"))
            names = {r[1] for r in rows}
            return col in names
        # Fallback generic reflection
        inspector = sa.inspect(bind)
        return col in [c['name'] for c in inspector.get_columns(table)]

    for table in ['workflow_runs','checkpoints','events','run_node_metrics','run_model_usage']:
        if not _has_col(table, 'tenant_id'):
            op.add_column(table, sa.Column('tenant_id', sa.String(), nullable=False, server_default='default'))
    
    # Update canvases table - need to drop and recreate primary key
    bind = op.get_bind()
    dialect = bind.dialect.name
    # For SQLite, simpler to recreate table when changing composite PK
    if dialect == 'sqlite':
        # Check if tenant_id already present (idempotent)
        cols = {r[1] for r in bind.execute(sa.text("PRAGMA table_info('canvases')"))}
        if 'tenant_id' not in cols:
            op.rename_table('canvases', 'canvases_old_tmp')
            op.create_table(
                'canvases',
                sa.Column('patient_id', sa.String(), nullable=False),
                sa.Column('agent_no', sa.Integer(), nullable=False),
                sa.Column('tenant_id', sa.String(), nullable=False, server_default='default'),
                sa.Column('version', sa.Integer(), nullable=False),
                sa.Column('content_md', sa.Text(), nullable=False),
                sa.Column('content_json', sa.JSON(), nullable=True),
                sa.Column('updated_by', sa.String(), nullable=False),
                sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP')),
                sa.PrimaryKeyConstraint('patient_id', 'agent_no', 'tenant_id')
            )
            # Copy data, set tenant_id to default
            bind.execute(sa.text("""
                INSERT INTO canvases (patient_id, agent_no, tenant_id, version, content_md, content_json, updated_by, updated_at)
                SELECT patient_id, agent_no, 'default', version, content_md, content_json, updated_by, updated_at FROM canvases_old_tmp
            """))
            op.drop_table('canvases_old_tmp')
    else:
        with op.batch_alter_table('canvases', schema=None) as batch_op:
            # Drop existing PK if present
            try:
                batch_op.drop_constraint('canvases_pkey', type_='primary')
            except Exception:
                pass
            batch_op.add_column(sa.Column('tenant_id', sa.String(), nullable=False, server_default='default'))
            batch_op.create_primary_key('canvases_pkey', ['patient_id', 'agent_no', 'tenant_id'])
    
    # Create tenant indexes if missing (SQLite simple check)
    index_specs = [
        ('workflow_runs','ix_workflow_runs_tenant'),
        ('checkpoints','ix_checkpoints_tenant'),
        ('canvases','ix_canvases_tenant'),
        ('events','ix_events_tenant'),
        ('run_node_metrics','ix_run_node_metrics_tenant'),
        ('run_model_usage','ix_run_model_usage_tenant'),
    ]
    for table, idx in index_specs:
        create = True
        if dialect == 'sqlite':
            existing = [r[1] for r in bind.execute(sa.text(f"PRAGMA index_list('{table}')"))]
            if idx in existing:
                create = False
        if create:
            op.create_index(idx, table, ['tenant_id'], unique=False)
    
    # ### end Alembic commands ###


def safe_drop_index(index_name: str, table_name: str):
    """Safely drop an index, ignoring if it doesn't exist."""
    try:
        op.drop_index(index_name, table_name=table_name)
    except Exception:
        # Index doesn't exist or already dropped
        pass


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Drop tenant indexes
    safe_drop_index('ix_run_model_usage_tenant', 'run_model_usage')
    safe_drop_index('ix_run_node_metrics_tenant', 'run_node_metrics')
    safe_drop_index('ix_events_tenant', 'events')
    safe_drop_index('ix_canvases_tenant', 'canvases')
    safe_drop_index('ix_checkpoints_tenant', 'checkpoints')
    safe_drop_index('ix_workflow_runs_tenant', 'workflow_runs')
    
    # Revert canvases table
    bind = op.get_bind()
    dialect = bind.dialect.name
    
    if dialect == 'sqlite':
        # For SQLite, recreate table without tenant_id
        cols = {r[1] for r in bind.execute(sa.text("PRAGMA table_info('canvases')"))}
        if 'tenant_id' in cols:
            op.rename_table('canvases', 'canvases_old_tmp')
            op.create_table(
                'canvases',
                sa.Column('patient_id', sa.String(), nullable=False),
                sa.Column('agent_no', sa.Integer(), nullable=False),
                sa.Column('version', sa.Integer(), nullable=False),
                sa.Column('content_md', sa.Text(), nullable=False),
                sa.Column('content_json', sa.JSON(), nullable=True),
                sa.Column('updated_by', sa.String(), nullable=False),
                sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP')),
                sa.PrimaryKeyConstraint('patient_id', 'agent_no')
            )
            # Copy data, exclude tenant_id
            bind.execute(sa.text("""
                INSERT INTO canvases (patient_id, agent_no, version, content_md, content_json, updated_by, updated_at)
                SELECT patient_id, agent_no, version, content_md, content_json, updated_by, updated_at FROM canvases_old_tmp
            """))
            op.drop_table('canvases_old_tmp')
    else:
        with op.batch_alter_table('canvases', schema=None) as batch_op:
            batch_op.drop_constraint('canvases_pkey', type_='primary')
            batch_op.drop_column('tenant_id')
            batch_op.create_primary_key('canvases_pkey', ['patient_id', 'agent_no'])
    
    # Drop tenant_id columns
    op.drop_column('run_model_usage', 'tenant_id')
    op.drop_column('run_node_metrics', 'tenant_id')
    op.drop_column('events', 'tenant_id')
    op.drop_column('checkpoints', 'tenant_id')
    op.drop_column('workflow_runs', 'tenant_id')
    
    # ### end Alembic commands ###